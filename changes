from langchain.llms import Ollama
from sentence_transformers import SentenceTransformer, util
import time
import re

# âœ… 1. Load Q&A from text file
def load_qa_from_file(filepath):
    with open(filepath, 'r', encoding='utf-8') as file:
        text = file.read()

    # Split based on Q: and A:
    qa_pairs = re.findall(r'Q:(.*?)A:(.*?)(?=Q:|$)', text, re.DOTALL)
    qa_pairs = [(q.strip(), a.strip()) for q, a in qa_pairs if q.strip() and a.strip()]
    return qa_pairs

qa_list = load_qa_from_file('qa.txt')

# âœ… 2. Load models
llm = Ollama(model="mistral")
embedder = SentenceTransformer('all-MiniLM-L6-v2')  # You can use another model too
threshold = 0.75  # similarity threshold

# âœ… 3. Evaluate
correct = 0
total = len(qa_list)

for idx, (question, expected_answer) in enumerate(qa_list):
    print(f"\nðŸ”¹ Question {idx+1}: {question}")

    try:
        generated_answer = llm.invoke(question)
        print(f"ðŸ”¸ Expected:  {expected_answer[:120]}...")
        print(f"ðŸ”¸ Generated: {generated_answer[:120]}...")
    except Exception as e:
        print(f"âŒ Error: {e}")
        continue

    embeddings = embedder.encode([expected_answer, generated_answer], convert_to_tensor=True)
    similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1]).item()
    print(f"ðŸ” Similarity Score: {similarity:.3f}")

    if similarity >= threshold:
        correct += 1

    time.sleep(1)

# âœ… 4. Final Results
accuracy = (correct / total) * 100 if total > 0 else 0
print(f"\n Total Questions: {total}")
print(f"Correct Matches (>{threshold}): {correct}")
print(f" Semantic Accuracy: {accuracy:.2f}%")
